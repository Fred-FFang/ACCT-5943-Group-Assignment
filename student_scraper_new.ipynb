{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lxml\n",
    "# %pip install html5lib\n",
    "# %pip install selenium\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install bs4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_companies(group_number): #get the group number from your lecturer\n",
    "    # File to store selected companies\n",
    "    selection_file = f'selected_companies_group_{group_number}.txt'\n",
    "    \n",
    "    # Check if we have already selected companies for this group\n",
    "    if os.path.exists(selection_file):\n",
    "        with open(selection_file, 'r') as f:\n",
    "            return [line.strip().split(',') for line in f.readlines()]\n",
    "    \n",
    "    # If not, perform the selection\n",
    "    rng = np.random.default_rng(group_number)  # Use group number as seed\n",
    "    companies = pd.read_csv(\"filtered_sp-500.csv\")\n",
    "    industries = list(set(companies['Sector']))\n",
    "    selected_industries = rng.choice(industries, size=min(10, len(industries)), replace=False) #select 10 industries\n",
    "\n",
    "    selected_companies = []\n",
    "    for industry in selected_industries:\n",
    "        industry_companies = companies[companies['Sector'] == industry].values.tolist()\n",
    "        selected_companies.extend(rng.choice(industry_companies, size=min(20, len(industry_companies)), replace=False)) #select 20 companies in each industry\n",
    "\n",
    "    # Convert numpy arrays to lists\n",
    "    selected_companies = [company.tolist() if isinstance(company, np.ndarray) else company for company in selected_companies]\n",
    "\n",
    "    # Save the selection\n",
    "    with open(selection_file, 'w') as f:\n",
    "        for company in selected_companies:\n",
    "            f.write(','.join(map(str, company)) + '\\n')\n",
    "\n",
    "    return selected_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_company_data(selected_companies, url):\n",
    "\n",
    "    # Setup Selenium WebDriver (you may need to adjust this based on your browser)\n",
    "    # You can see this scraping process in action\n",
    "    driver = webdriver.Chrome()  # or webdriver.Firefox()\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"#dataTable tbody tr\"))\n",
    "        )\n",
    "\n",
    "        all_data = []\n",
    "        company_codes = [company[0] for company in selected_companies]  # Extract company codes\n",
    "\n",
    "        while True:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Extract headers from the appropriate div\n",
    "            header_table = soup.find('div', {'class': 'dataTables_scrollHead'})\n",
    "            if header_table is None:\n",
    "                print(\"Table not found. Please check the HTML structure.\")\n",
    "                break\n",
    "            headers = [header.text.strip() for header in header_table.find_all('th')]\n",
    "            \n",
    "            # Extract rows from the table body\n",
    "            table_body = soup.find(\"table\", id='dataTable')\n",
    "            rows = []\n",
    "            for row in table_body.find_all('tr'):\n",
    "                cols = [ele.text.strip() for ele in row.find_all('td')]\n",
    "                if len(cols) > 0 and cols[0].split('-')[0] in company_codes:\n",
    "                    rows.append(cols)\n",
    "                \n",
    "            # Convert to DataFrame and append if data matches selected companies\n",
    "            if rows:\n",
    "                df = pd.DataFrame(rows, columns=headers)\n",
    "                all_data.append(df)\n",
    "\n",
    "            # Check if there's a next page\n",
    "            try:\n",
    "                next_button = driver.find_element(By.CSS_SELECTOR, \"#dataTable_next:not(.disabled)\")\n",
    "                next_button.click()\n",
    "                time.sleep(1)  # Wait for the page to load\n",
    "            except:\n",
    "                break  # No more pages\n",
    "\n",
    "        # Combine all data\n",
    "        if all_data:\n",
    "            final_data = pd.concat(all_data, ignore_index=True)\n",
    "        else:\n",
    "            final_data = pd.DataFrame()  # Return empty DataFrame if no data is found\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADM (Consumer Staples)\n",
      "AEE (Utilities)\n",
      "AEP (Utilities)\n",
      "AFL (Financials)\n",
      "AIG (Financials)\n",
      "AKAM (Information Technology)\n",
      "ALB (Materials)\n",
      "AME (Industrials)\n",
      "AMT (Real Estate)\n",
      "ANET (Information Technology)\n",
      "ANSS (Information Technology)\n",
      "APH (Information Technology)\n",
      "APTV (Consumer Discretionary)\n",
      "AVY (Materials)\n",
      "AWK (Utilities)\n",
      "AXP (Financials)\n",
      "BA (Industrials)\n",
      "BALL (Materials)\n",
      "BK (Financials)\n",
      "BKNG (Consumer Discretionary)\n",
      "BKR (Energy)\n",
      "BLDR (Industrials)\n",
      "BRO (Financials)\n",
      "BWA (Consumer Discretionary)\n",
      "BXP (Real Estate)\n",
      "CBOE (Financials)\n",
      "CCI (Real Estate)\n",
      "CDNS (Information Technology)\n",
      "CE (Materials)\n",
      "CF (Materials)\n",
      "CHD (Consumer Staples)\n",
      "CHTR (Communication Services)\n",
      "CL (Consumer Staples)\n",
      "CMCSA (Communication Services)\n",
      "CMG (Consumer Discretionary)\n",
      "CMI (Industrials)\n",
      "CMS (Utilities)\n",
      "CNP (Utilities)\n",
      "COF (Financials)\n",
      "COP (Energy)\n",
      "CPAY (Financials)\n",
      "CPT (Real Estate)\n",
      "CTRA (Energy)\n",
      "CTSH (Information Technology)\n",
      "CVX (Energy)\n",
      "D (Utilities)\n",
      "DD (Materials)\n",
      "DLR (Real Estate)\n",
      "DOV (Industrials)\n",
      "DOW (Materials)\n",
      "DPZ (Consumer Discretionary)\n",
      "DTE (Utilities)\n",
      "DUK (Utilities)\n",
      "DVN (Energy)\n",
      "ED (Utilities)\n",
      "EG (Financials)\n",
      "EIX (Utilities)\n",
      "EMN (Materials)\n",
      "ENPH (Information Technology)\n",
      "EOG (Energy)\n",
      "EPAM (Information Technology)\n",
      "EQR (Real Estate)\n",
      "EQT (Energy)\n",
      "ESS (Real Estate)\n",
      "ETR (Utilities)\n",
      "ETSY (Consumer Discretionary)\n",
      "EXPD (Industrials)\n",
      "FANG (Energy)\n",
      "FAST (Industrials)\n",
      "FCX (Materials)\n",
      "FSLR (Information Technology)\n",
      "FTNT (Information Technology)\n",
      "GD (Industrials)\n",
      "GDDY (Information Technology)\n",
      "GE (Industrials)\n",
      "GL (Financials)\n",
      "GM (Consumer Discretionary)\n",
      "GNRC (Industrials)\n",
      "GOOG (Communication Services)\n",
      "GOOGL (Communication Services)\n",
      "GRMN (Consumer Discretionary)\n",
      "HAL (Energy)\n",
      "HES (Energy)\n",
      "HIG (Financials)\n",
      "HLT (Consumer Discretionary)\n",
      "HON (Industrials)\n",
      "HST (Real Estate)\n",
      "HSY (Consumer Staples)\n",
      "IFF (Materials)\n",
      "INTC (Information Technology)\n",
      "IP (Materials)\n",
      "IPG (Communication Services)\n",
      "IRM (Real Estate)\n",
      "JNPR (Information Technology)\n",
      "K (Consumer Staples)\n",
      "KDP (Consumer Staples)\n",
      "KEY (Financials)\n",
      "KHC (Consumer Staples)\n",
      "KIM (Real Estate)\n",
      "KMB (Consumer Staples)\n",
      "KMI (Energy)\n",
      "KO (Consumer Staples)\n",
      "LDOS (Industrials)\n",
      "LHX (Industrials)\n",
      "LNT (Utilities)\n",
      "LYB (Materials)\n",
      "LYV (Communication Services)\n",
      "MAA (Real Estate)\n",
      "MAS (Industrials)\n",
      "MCD (Consumer Discretionary)\n",
      "MDLZ (Consumer Staples)\n",
      "MET (Financials)\n",
      "META (Communication Services)\n",
      "MGM (Consumer Discretionary)\n",
      "MHK (Consumer Discretionary)\n",
      "MLM (Materials)\n",
      "MMM (Industrials)\n",
      "MNST (Consumer Staples)\n",
      "MO (Consumer Staples)\n",
      "MOS (Materials)\n",
      "MPC (Energy)\n",
      "MRO (Energy)\n",
      "MSCI (Financials)\n",
      "MSI (Information Technology)\n",
      "MTCH (Communication Services)\n",
      "NCLH (Consumer Discretionary)\n",
      "NDAQ (Financials)\n",
      "NEE (Utilities)\n",
      "NEM (Materials)\n",
      "NFLX (Communication Services)\n",
      "NI (Utilities)\n",
      "NOW (Information Technology)\n",
      "NRG (Utilities)\n",
      "NUE (Materials)\n",
      "NVR (Consumer Discretionary)\n",
      "NXPI (Information Technology)\n",
      "O (Real Estate)\n",
      "OKE (Energy)\n",
      "OMC (Communication Services)\n",
      "OXY (Energy)\n",
      "PARA (Communication Services)\n",
      "PEG (Utilities)\n",
      "PEP (Consumer Staples)\n",
      "PFG (Financials)\n",
      "PGR (Financials)\n",
      "PHM (Consumer Discretionary)\n",
      "PKG (Materials)\n",
      "PLD (Real Estate)\n",
      "PM (Consumer Staples)\n",
      "PNW (Utilities)\n",
      "PSA (Real Estate)\n",
      "PSX (Energy)\n",
      "PWR (Industrials)\n",
      "RCL (Consumer Discretionary)\n",
      "REG (Real Estate)\n",
      "RF (Financials)\n",
      "ROP (Information Technology)\n",
      "SBAC (Real Estate)\n",
      "SCHW (Financials)\n",
      "SHW (Materials)\n",
      "SLB (Energy)\n",
      "SPG (Real Estate)\n",
      "SRE (Utilities)\n",
      "STLD (Materials)\n",
      "SWK (Industrials)\n",
      "T (Communication Services)\n",
      "TAP (Consumer Staples)\n",
      "TDY (Information Technology)\n",
      "TFC (Financials)\n",
      "TMUS (Communication Services)\n",
      "TRGP (Energy)\n",
      "TSCO (Consumer Discretionary)\n",
      "TSLA (Consumer Discretionary)\n",
      "TYL (Information Technology)\n",
      "UBER (Industrials)\n",
      "UDR (Real Estate)\n",
      "UNP (Industrials)\n",
      "VLO (Energy)\n",
      "VMC (Materials)\n",
      "VRSN (Information Technology)\n",
      "VTR (Real Estate)\n",
      "VZ (Communication Services)\n",
      "WEC (Utilities)\n",
      "WM (Industrials)\n",
      "WY (Real Estate)\n",
      "WYNN (Consumer Discretionary)\n",
      "XEL (Utilities)\n",
      "XOM (Energy)\n",
      "YUM (Consumer Discretionary)\n",
      "Data Scraping finished, please check your data in the csv file\n",
      "Data saved to group_53_data.csv\n"
     ]
    }
   ],
   "source": [
    "def main(group_number, url):\n",
    "    selected_companies = select_companies(group_number)\n",
    "    company_data = scrape_company_data(selected_companies, url)\n",
    "\n",
    "    sorted_companies = sorted(selected_companies, key=lambda x: x[0])\n",
    "    for company in sorted_companies:\n",
    "        print(f\"{company[0]} ({company[2]})\")\n",
    "\n",
    "    print(\"Data Scraping finished, please check your data in the csv file\")\n",
    "    company_data.to_csv(f\"group_{group_number}_data.csv\", index=False)\n",
    "    print(f\"Data saved to group_{group_number}_data.csv\")\n",
    "\n",
    "url = \"https://unsw-yahoo-finance.github.io/ACCT5943/\" # Replace with the actual website\n",
    "# TODO: update the group_number to your assigned group number, then click run-all\n",
    "group_number = 53\n",
    "main(group_number, url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
